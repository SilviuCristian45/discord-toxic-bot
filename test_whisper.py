from faster_whisper import WhisperModel
import time
import os

# Alegem modelul. 
# Optiuni: "tiny", "base", "small", "medium", "large-v3"
# "tiny" e cel mai rapid (aproape instant). "base" e un balans bun. "small" e deja lent pe CPU.
MODEL_SIZE = "base.en" # .en = model specific pt engleza (mai rapid decat cel multilingv)

print(f"â³ ÃncÄƒrcare model '{MODEL_SIZE}'...")
start_load = time.time()

# device="cpu" pentru ca esti pe WSL fara GPU passthrough probabil. 
# compute_type="int8" face magia de viteza.
model = WhisperModel(MODEL_SIZE, device="cpu", compute_type="int8")

end_load = time.time()
print(f"âœ… Model Ã®ncÄƒrcat Ã®n {end_load - start_load:.2f} secunde!")

print("-" * 30)
print("Pentru test, ai nevoie de un fiÈ™ier audio 'test.wav' Ã®n folder.")
print("DacÄƒ nu ai, scriptul se va opri aici.")

# VerificÄƒm dacÄƒ ai un fiÈ™ier de test (opÈ›ional)
if os.path.exists("test.wav"):
    print("ğŸ¤ Ãncep transcrierea...")
    start_transcribe = time.time()
    
    segments, info = model.transcribe("test.wav", beam_size=5)
    
    full_text = ""
    for segment in segments:
        full_text += segment.text + " "
        
    end_transcribe = time.time()
    
    print(f"ğŸ“ Text: {full_text}")
    print(f"â±ï¸ Timp transcriere: {end_transcribe - start_transcribe:.2f} secunde")
else:
    print("âš ï¸ Pune un fiÈ™ier 'test.wav' scurt aici ca sÄƒ testezi viteza de transcriere.")
